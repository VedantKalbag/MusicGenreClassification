{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 08:20:36.967442: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model, models, layers, mixed_precision\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, Flatten, Dense, Reshape, Conv2DTranspose, Activation, Conv1D, MaxPooling1D, AveragePooling1D, UpSampling1D, Conv1DTranspose\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import sys, os, pickle, numpy as np, pandas as pd\n",
    "\n",
    "# import autoencoder\n",
    "\n",
    "from kapre import STFT, Magnitude, MagnitudeToDecibel\n",
    "from kapre.composed import get_melspectrogram_layer, get_log_frequency_spectrogram_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(data_path='../../datasets/denoising', lr=5e-05, epochs=5, batch=16, log_step=10, multi_gpu=False, gpu=2, suffix='denoising_AE')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import namedtuple\n",
    "from json import JSONEncoder\n",
    "\n",
    "def customJSONDecoder(JSONDict):\n",
    "    return namedtuple('Namespace', JSONDict.keys())(*JSONDict.values())\n",
    "\n",
    "config = json.load(open('./autoencoder_config.json'), object_hook=customJSONDecoder)\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Autoencoder model for denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import librosa\n",
    "# path='../../datasets/gtzan10sAug/datasets/snr5Full/audio/cleanAudio'\n",
    "# output_path = '../../datasets/denoising/clean'\n",
    "\n",
    "# dirName, splits, _ = next(os.walk(path))\n",
    "# # print(splits)\n",
    "# for split in splits:\n",
    "#     print(split)\n",
    "#     if not os.path.exists(os.path.join(output_path,split)):\n",
    "#         print(\"Creating output directory for: \", split)\n",
    "#         os.makedirs(os.path.join(output_path,split))\n",
    "#     _,subdirs,_ = next(os.walk(os.path.join(path, split)))\n",
    "#     for subdir in subdirs:\n",
    "#         print(subdir)\n",
    "#         _,_,filelist = next(os.walk(os.path.join(path, split, subdir)))\n",
    "#         for f in filelist:\n",
    "#             fname = f[:-4]\n",
    "#             x,sr = librosa.load(os.path.join(path, split, subdir, f))\n",
    "#             np.save(os.path.join(output_path, split,f'{fname}.npy'),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioLoader(keras.utils.Sequence):\n",
    "    def __init__(self, mode, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        self.pos = np.random.randint(0,220500-66150)\n",
    "        np.random.seed(42)\n",
    "\n",
    "        self.clean_suffix = 'clean'\n",
    "        self.augmented_suffix = 'augmented'\n",
    "\n",
    "\n",
    "        if self.mode == 'train': \n",
    "            self.noisy_path = os.path.join(config.data_path, self.augmented_suffix,'train')\n",
    "            self.clean_path = os.path.join(config.data_path, self.clean_suffix,'train')\n",
    "        if self.mode == 'test':\n",
    "            self.noisy_path = os.path.join(config.data_path, self.augmented_suffix,'test')\n",
    "            self.clean_path = os.path.join(config.data_path, self.clean_suffix,'test')\n",
    "        if self.mode == 'val':\n",
    "            self.noisy_path = os.path.join(config.data_path, self.augmented_suffix,'val')\n",
    "            self.clean_path = os.path.join(config.data_path, self.clean_suffix,'val')\n",
    "        # print(os.path.exists(self.data_path))\n",
    "        _,_,self.filenames = next(os.walk(self.noisy_path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.filenames) // self.batch_size)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        try:\n",
    "            source = np.empty((self.batch_size, 220500))#66150))#220500))\n",
    "            target = np.empty((self.batch_size, 220500))#66150))#220500))\n",
    "            batch = self.filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "            for i, ID in enumerate(batch):\n",
    "                tmp = np.load(os.path.join(self.noisy_path, ID), allow_pickle=True)\n",
    "                source[i] = tmp[0]#[self.pos:self.pos+660150]\n",
    "                tmp2 = np.load(os.path.join(self.clean_path, f'{ID.split(\"_\")[0]}.npy'), allow_pickle=True)\n",
    "                target[i] = tmp2[0]#[self.pos:self.pos+660150]\n",
    "            return source,target#X,y #bat[:,0], bat[:,1]\n",
    "        except Exception as e:\n",
    "            print(i, ID)\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = AudioLoader('train', 32)\n",
    "val = AudioLoader('val',32)\n",
    "test = AudioLoader('test', 32)\n",
    "config = json.load(open('./autoencoder_config.json'), object_hook=customJSONDecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11665034"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(os.path.join(train.noisy_path,train.filenames[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.11665034, -0.11665034, -0.11665034, ..., -0.11665034,\n",
       "         -0.11665034, -0.11665034],\n",
       "        [-0.14452517, -0.14452517, -0.14452517, ..., -0.14452517,\n",
       "         -0.14452517, -0.14452517],\n",
       "        [ 0.11407971,  0.11407971,  0.11407971, ...,  0.11407971,\n",
       "          0.11407971,  0.11407971],\n",
       "        ...,\n",
       "        [-0.02606082, -0.02606082, -0.02606082, ..., -0.02606082,\n",
       "         -0.02606082, -0.02606082],\n",
       "        [ 0.01890647,  0.01890647,  0.01890647, ...,  0.01890647,\n",
       "          0.01890647,  0.01890647],\n",
       "        [ 0.02381718,  0.02381718,  0.02381718, ...,  0.02381718,\n",
       "          0.02381718,  0.02381718]]),\n",
       " array([[ 0.07775879,  0.07775879,  0.07775879, ...,  0.07775879,\n",
       "          0.07775879,  0.07775879],\n",
       "        [-0.0295105 , -0.0295105 , -0.0295105 , ..., -0.0295105 ,\n",
       "         -0.0295105 , -0.0295105 ],\n",
       "        [ 0.02835083,  0.02835083,  0.02835083, ...,  0.02835083,\n",
       "          0.02835083,  0.02835083],\n",
       "        ...,\n",
       "        [-0.10968018, -0.10968018, -0.10968018, ..., -0.10968018,\n",
       "         -0.10968018, -0.10968018],\n",
       "        [-0.10699463, -0.10699463, -0.10699463, ..., -0.10699463,\n",
       "         -0.10699463, -0.10699463],\n",
       "        [ 0.23999023,  0.23999023,  0.23999023, ...,  0.23999023,\n",
       "          0.23999023,  0.23999023]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # STACKOVERFLOW EXAMPLE\n",
    "\n",
    "# input_sig = Input(batch_shape=(1,128,1))\n",
    "# x = Conv1D(8,3, activation='relu', padding='same',dilation_rate=2)(input_sig)\n",
    "# x1 = MaxPooling1D(2)(x)\n",
    "# x2 = Conv1D(4,3, activation='relu', padding='same',dilation_rate=2)(x1)\n",
    "# x3 = MaxPooling1D(2)(x2)\n",
    "# x4 = AveragePooling1D()(x3)\n",
    "# flat = Flatten()(x4)\n",
    "# encoded = Dense(2)(flat)\n",
    "# d1 = Dense(64)(encoded)\n",
    "# d2 = Reshape((16,4))(d1)\n",
    "# d3 = Conv1D(4,1,strides=1, activation='relu', padding='same')(d2)\n",
    "# d4 = UpSampling1D(2)(d3)\n",
    "# d5 = Conv1D(8,1,strides=1, activation='relu', padding='same')(d4)\n",
    "# d6 = UpSampling1D(2)(d5)\n",
    "# d7 = UpSampling1D(2)(d6)\n",
    "# decoded = Conv1D(1,1,strides=1, activation='sigmoid', padding='same')(d7)\n",
    "# model= Model(input_sig, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(layers):\n",
    "    if layers == 1:\n",
    "        input_sig = Input(batch_shape=(32,220500,1))\n",
    "        x = Conv1D(32,2048, activation='relu', padding='same')(input_sig)\n",
    "        d3 = Conv1DTranspose(32,2048,activation='relu', padding='same')(x)\n",
    "        decoded = Conv1D(1,1,strides=1, activation='sigmoid', padding='same')(d3)\n",
    "        model= Model(input_sig, decoded)\n",
    "    if layers == 3:\n",
    "        input_sig = Input(batch_shape=(32,220500,1))\n",
    "        # ENCODER\n",
    "        x1 = Conv1D(128,2048, activation='relu', padding='same')(input_sig)\n",
    "        x2 = Conv1D(64,2048, activation='relu',padding='same')(x1)\n",
    "        x3 = Conv1D(32,2048, activation='relu',padding='same')(x2)\n",
    "        # BOTTLENECK\n",
    "        B = Dense(24)(x3)\n",
    "        # DECODER\n",
    "        d1 = Conv1DTranspose(32,2048, activation='relu',padding='same')(B)\n",
    "        d2 = Conv1DTranspose(64, 2048, activation='relu',padding='same')(d1)\n",
    "        d3 = Conv1DTranspose(128,2048,activation='relu', padding='same')(d2)\n",
    "        # OUTPUT LAYER\n",
    "        decoded = Conv1D(1,1,strides=1, activation='sigmoid', padding='same')(d3)\n",
    "        model= Model(input_sig, decoded)\n",
    "    \n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(32, 220500, 1)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (32, 220500, 128)         262272    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (32, 220500, 64)          8388672   \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (32, 220500, 32)          1048608   \n",
      "                                                                 \n",
      " dense (Dense)               (32, 220500, 24)          792       \n",
      "                                                                 \n",
      " conv1d_transpose (Conv1DTra  (32, 220500, 32)         393248    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv1d_transpose_1 (Conv1DT  (32, 220500, 64)         2097216   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv1d_transpose_2 (Conv1DT  (32, 220500, 128)        16777344  \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (32, 220500, 1)           129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,968,281\n",
      "Trainable params: 28,968,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 07:59:59.152011: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-16 08:00:00.470042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9650 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "2022-07-16 08:00:00.470944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9650 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:18:00.0, compute capability: 7.5\n",
      "2022-07-16 08:00:00.471708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 9649 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_sig = Input(batch_shape=(32,220500,1))\n",
    "# ENCODER\n",
    "x1 = Conv1D(128,2048, activation='relu', padding='same')(input_sig)\n",
    "x2 = Conv1D(64,1024, activation='relu',padding='same')(x1)\n",
    "x3 = Conv1D(32,512, activation='relu',padding='same')(x2)\n",
    "# BOTTLENECK\n",
    "B = Dense(24)(x3)\n",
    "# DECODER\n",
    "d1 = Conv1DTranspose(32,512, activation='relu',padding='same')(B)\n",
    "d2 = Conv1DTranspose(64, 1024, activation='relu',padding='same')(d1)\n",
    "d3 = Conv1DTranspose(128,2048,activation='relu', padding='same')(d2)\n",
    "# OUTPUT LAYER\n",
    "decoded = Conv1D(1,1,strides=1, activation='sigmoid', padding='same')(d3)\n",
    "model= Model(input_sig, decoded)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_37 (InputLayer)       [(32, 220500, 1)]         0         \n",
      "                                                                 \n",
      " conv1d_95 (Conv1D)          (32, 216, 32)             65568     \n",
      "                                                                 \n",
      " conv1d_transpose_1 (Conv1DT  (32, 222208, 32)         2097184   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv1d_96 (Conv1D)          (32, 222208, 1)           33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,162,785\n",
      "Trainable params: 2,162,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# bottleneck_dim = 16\n",
    "\n",
    "# input_sig = Input(batch_shape=(32,220500,1))\n",
    "# x = Conv1D(32,2048, strides=1024, activation='relu', padding='same')(input_sig)\n",
    "# # x1 = MaxPooling1D(2)(x)\n",
    "# # x2 = Conv1D(4,3, activation='relu', padding='same',dilation_rate=2)(x1)\n",
    "# # x3 = MaxPooling1D(2)(x2)\n",
    "# # x4 = AveragePooling1D()(x3)\n",
    "# # flat = Flatten()(x)\n",
    "# # encoded = Dense(bottleneck_dim)(flat)\n",
    "# # d1 = Dense(bottleneck_dim)(encoded)\n",
    "# # d2 = Reshape((16,4))(d1)\n",
    "# d3 = Conv1DTranspose(32,2048,strides=1024, activation='relu', padding='same')(x)#(d2)\n",
    "# # d4 = UpSampling1D(256)(d3)\n",
    "# # d5 = Conv1D(8,1,strides=1, activation='relu', padding='same')(d4)\n",
    "# # d6 = UpSampling1D(2)(d5)\n",
    "# # d7 = UpSampling1D(2)(d6)\n",
    "# decoded = Conv1D(1,1,strides=1, activation='sigmoid', padding='same')(d3)\n",
    "# model= Model(input_sig, decoded)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-15 09:17:14.741752: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/41 [=>............................] - ETA: 19:31 - loss: 0.1958"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/usr/research/drive/Vedant/src/denoising_autoencoders.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776f726b222c2273657474696e6773223a7b22686f7374223a227373683a2f2f636f63686c2e697074696d652e6f7267227d7d/usr/research/drive/Vedant/src/denoising_autoencoders.ipynb#ch0000017vscode-remote?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mlr), loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mMeanSquaredError())\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776f726b222c2273657474696e6773223a7b22686f7374223a227373683a2f2f636f63686c2e697074696d652e6f7267227d7d/usr/research/drive/Vedant/src/denoising_autoencoders.ipynb#ch0000017vscode-remote?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train, validation_data\u001b[39m=\u001b[39;49mval, epochs\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mepochs)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776f726b222c2273657474696e6773223a7b22686f7374223a227373683a2f2f636f63686c2e697074696d652e6f7267227d7d/usr/research/drive/Vedant/src/denoising_autoencoders.ipynb#ch0000017vscode-remote?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mevaluate(test)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1414\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1414\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1416\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   hook(batch, logs)\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1106\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1107\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py:607\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    605\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 607\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py:916\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py:916\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py:601\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    599\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    600\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 601\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    602\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \n\u001b[1;32m   1138\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=config.lr), loss=tf.keras.losses.MeanSquaredError())\n",
    "history = model.fit(train, validation_data=val, epochs=config.epochs)\n",
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.log10(history.history['loss']))\n",
    "plt.plot(np.log10(history.history['val_loss']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104210</td>\n",
       "      <td>0.040097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035733</td>\n",
       "      <td>0.030683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029753</td>\n",
       "      <td>0.027166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026775</td>\n",
       "      <td>0.025124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.024940</td>\n",
       "      <td>0.023876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.023755</td>\n",
       "      <td>0.023086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.023001</td>\n",
       "      <td>0.022584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.022520</td>\n",
       "      <td>0.022248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.022186</td>\n",
       "      <td>0.022057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.021977</td>\n",
       "      <td>0.021917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.021829</td>\n",
       "      <td>0.021822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.021722</td>\n",
       "      <td>0.021758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.021647</td>\n",
       "      <td>0.021712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.021589</td>\n",
       "      <td>0.021679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.021545</td>\n",
       "      <td>0.021654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.021511</td>\n",
       "      <td>0.021635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.021485</td>\n",
       "      <td>0.021618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.021462</td>\n",
       "      <td>0.021607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.021444</td>\n",
       "      <td>0.021597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.021589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.021417</td>\n",
       "      <td>0.021583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.021406</td>\n",
       "      <td>0.021577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.021397</td>\n",
       "      <td>0.021573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.021389</td>\n",
       "      <td>0.021570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.021383</td>\n",
       "      <td>0.021566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.021377</td>\n",
       "      <td>0.021564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.021372</td>\n",
       "      <td>0.021562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.021367</td>\n",
       "      <td>0.021560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.021363</td>\n",
       "      <td>0.021558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.021359</td>\n",
       "      <td>0.021557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.021356</td>\n",
       "      <td>0.021556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.021353</td>\n",
       "      <td>0.021555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.021351</td>\n",
       "      <td>0.021554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.021348</td>\n",
       "      <td>0.021553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.021346</td>\n",
       "      <td>0.021553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.021344</td>\n",
       "      <td>0.021552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.021342</td>\n",
       "      <td>0.021552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.021340</td>\n",
       "      <td>0.021551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.021339</td>\n",
       "      <td>0.021551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.021338</td>\n",
       "      <td>0.021551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.021336</td>\n",
       "      <td>0.021550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.021335</td>\n",
       "      <td>0.021550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.021334</td>\n",
       "      <td>0.021550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.021333</td>\n",
       "      <td>0.021550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.021332</td>\n",
       "      <td>0.021550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.021331</td>\n",
       "      <td>0.021550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.021330</td>\n",
       "      <td>0.021550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.021550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.021550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.021328</td>\n",
       "      <td>0.021550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  val_loss\n",
       "0   0.104210  0.040097\n",
       "1   0.035733  0.030683\n",
       "2   0.029753  0.027166\n",
       "3   0.026775  0.025124\n",
       "4   0.024940  0.023876\n",
       "5   0.023755  0.023086\n",
       "6   0.023001  0.022584\n",
       "7   0.022520  0.022248\n",
       "8   0.022186  0.022057\n",
       "9   0.021977  0.021917\n",
       "10  0.021829  0.021822\n",
       "11  0.021722  0.021758\n",
       "12  0.021647  0.021712\n",
       "13  0.021589  0.021679\n",
       "14  0.021545  0.021654\n",
       "15  0.021511  0.021635\n",
       "16  0.021485  0.021618\n",
       "17  0.021462  0.021607\n",
       "18  0.021444  0.021597\n",
       "19  0.021429  0.021589\n",
       "20  0.021417  0.021583\n",
       "21  0.021406  0.021577\n",
       "22  0.021397  0.021573\n",
       "23  0.021389  0.021570\n",
       "24  0.021383  0.021566\n",
       "25  0.021377  0.021564\n",
       "26  0.021372  0.021562\n",
       "27  0.021367  0.021560\n",
       "28  0.021363  0.021558\n",
       "29  0.021359  0.021557\n",
       "30  0.021356  0.021556\n",
       "31  0.021353  0.021555\n",
       "32  0.021351  0.021554\n",
       "33  0.021348  0.021553\n",
       "34  0.021346  0.021553\n",
       "35  0.021344  0.021552\n",
       "36  0.021342  0.021552\n",
       "37  0.021340  0.021551\n",
       "38  0.021339  0.021551\n",
       "39  0.021338  0.021551\n",
       "40  0.021336  0.021550\n",
       "41  0.021335  0.021550\n",
       "42  0.021334  0.021550\n",
       "43  0.021333  0.021550\n",
       "44  0.021332  0.021550\n",
       "45  0.021331  0.021550\n",
       "46  0.021330  0.021550\n",
       "47  0.021329  0.021550\n",
       "48  0.021329  0.021550\n",
       "49  0.021328  0.021550"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(history.history)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 2s 80ms/step\n"
     ]
    }
   ],
   "source": [
    "cleaned = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "864"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(864, 1, 1)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AudioLoader' object has no attribute 'to_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/usr/research/drive/Vedant/src/denoising_autoencoders.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f776f726b222c2273657474696e6773223a7b22686f7374223a227373683a2f2f636f63686c2e697074696d652e6f7267227d7d/usr/research/drive/Vedant/src/denoising_autoencoders.ipynb#ch0000042vscode-remote?line=0'>1</a>\u001b[0m model(test\u001b[39m.\u001b[39;49mto_tensor())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AudioLoader' object has no attribute 'to_tensor'"
     ]
    }
   ],
   "source": [
    "model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "test_file = np.load('../../datasets/denoising/augmented/test/blues.00012.0_street_traffic-prague-1153-42960-a_h146_Outside_MITCampus_1txts.npy')\n",
    "input_tensor = np.expand_dims(test_file, axis=0)\n",
    "cleaned = model.predict(input_tensor)\n",
    "# import soundfile as sf\n",
    "# sf.write('denoised_file.wav', cleaned, 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00559153]]], dtype=float32)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 04:38:43.361217: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-16 04:38:44.694218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9650 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "2022-07-16 04:38:44.695098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9650 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:18:00.0, compute capability: 7.5\n",
      "2022-07-16 04:38:44.695848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 9649 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('../models/denoising_AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = np.load('../../datasets/denoising/augmented/test/blues.00012.0_street_traffic-prague-1153-42960-a_h146_Outside_MITCampus_1txts.npy')\n",
    "input_tensor = np.expand_dims(test_file, axis=0)\n",
    "x = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 220500, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "sf.write('denoised_file.wav', np.squeeze(x.numpy()), 22050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
