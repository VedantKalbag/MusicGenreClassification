{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 05:10:44.919184: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, mixed_precision\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import gc\n",
    "import sys, os, pickle, numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path':'../../datasets/gtzan10sAug/datasets/AE1snr1BalAug/',\n",
    "    'lr':1e-3,\n",
    "    'epochs':10,\n",
    "    'batch':256,\n",
    "    'log_step':10,\n",
    "    'multi_gpu':False,\n",
    "    'gpu':2,\n",
    "    'suffix':'denoising_AE',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from operator import truediv\n",
    "parser = argparse.ArgumentParser()\n",
    "# Model configuration.\n",
    "parser.add_argument('--data_path',type=str, default='../../datasets/gtzan10sAug/datasets/AE1snr1BalAug/', help='path to the folder containing train, test and val folders')\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help='learning rate')\n",
    "parser.add_argument('--epochs', type=int, default=10, help='num epochs')\n",
    "parser.add_argument('--multigpu', type=int, default=0, help='Train on multiple GPUs')\n",
    "parser.add_argument('--gpu', type=str, default=2, help='GPU to use for training')\n",
    "parser.add_argument('--log_step', type=int, default=10, help='log interval')\n",
    "parser.add_argument('--batch', type=int, default = 256, help='Batch Size')\n",
    "parser.add_argument('--suffix',type=str, default='denoising_AE', help='Model Name Suffix')\n",
    "config = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedDataset(keras.utils.Sequence):\n",
    "    def __init__(self, mode, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train': \n",
    "            self.noisy_path = os.path.join(config.data_path, 'features','train')\n",
    "            self.clean_path = os.path.join(config.data_path, 'featuresClean','train')\n",
    "        if self.mode == 'test':\n",
    "            self.noisy_path = os.path.join(config.data_path, 'features','test')\n",
    "            self.clean_path = os.path.join(config.data_path, 'featuresClean','test')\n",
    "        if self.mode == 'val':\n",
    "            self.noisy_path = os.path.join(config.data_path, 'features','val')\n",
    "            self.clean_path = os.path.join(config.data_path, 'featuresClean','val')\n",
    "        # print(os.path.exists(self.data_path))\n",
    "        _,_,self.filenames = next(os.walk(self.noisy_path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.filenames) // self.batch_size)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        try:\n",
    "            source = np.empty((self.batch_size, 128,130))\n",
    "            target = np.empty((self.batch_size, 128,130))\n",
    "            batch = self.filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "            for i, ID in enumerate(batch):\n",
    "                tmp = np.load(os.path.join(self.noisy_path, ID), allow_pickle=True)\n",
    "                source[i] = tmp[0]\n",
    "                tmp2 = np.load(os.path.join(self.clean_path, ID), allow_pickle=True)\n",
    "                target[i] = tmp2[0]\n",
    "            return source,target#X,y #bat[:,0], bat[:,1]\n",
    "        except Exception as e:\n",
    "            print(i, ID)\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = AugmentedDataset('train',256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 130)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(os.path.join(train.noisy_path, '949.npy'), allow_pickle=True)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 108)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(os.path.join(train.clean_path, '949.npy'), allow_pickle=True)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 949.npy\n",
      "could not broadcast input array from shape (128,108) into shape (128,130)\n"
     ]
    }
   ],
   "source": [
    "next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
