{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, mixed_precision\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import gc\n",
    "\n",
    "df = pd.DataFrame(np.load('../datasets/gtzan10sAug/Final/features/a0.5_min1.0_max10.0_3.0s_block_0.5s_hop.npy', allow_pickle=True), columns=['melspec','label','filename'])\n",
    "X = np.stack(df[['melspec','filename']].values)\n",
    "y = df['label'].to_numpy()\n",
    "names = df['filename'].to_numpy()\n",
    "del df\n",
    "gc.collect()\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{  \n",
    "\n",
    "    'blues': 0,  \n",
    "    'classical': 1,  \n",
    "    'country': 2,  \n",
    "    'disco': 3,  \n",
    "    'hiphop': 4,  \n",
    "    'jazz': 5,  \n",
    "    'metal': 6,  \n",
    "    'pop': 7,  \n",
    "    'reggae': 8,  \n",
    "    'rock': 9   \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.30, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, x_val, y_test, y_val = train_test_split(x_val, y_val, test_size=0.50, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_train.npy', x_train)\n",
    "np.save('x_test.npy',x_test)\n",
    "np.save('x_val.npy',x_val)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy',y_test)\n",
    "np.save('y_val.npy', y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df['melspec'] = list(x_train[:,0])\n",
    "df['label'] = y_train\n",
    "df['filename'] = x_train[:,1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in tqdm(df.iterrows()):\n",
    "    filename = row['filename']\n",
    "    np.save(f'../datasets/gtzan10sAug/vedant/train/{filename}.npy',row[['melspec','label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "_,_,filenames = next(os.walk('../datasets/gtzan10sAug/vedant/train'))\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedDataset(keras.utils.Sequence):\n",
    "    def __init__(self, mode, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "            self.data_path = '../datasets/gtzan10sAug/vedant/train'\n",
    "        if self.mode == 'test':\n",
    "            self.data_path = '../datasets/gtzan10sAug/vedant/test'\n",
    "        if self.mode == 'val':\n",
    "            self.data_path = '../datasets/gtzan10sAug/vedant/val'\n",
    "        _,_,self.filenames = next(os.walk(self.data_path))\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        batch = self.filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        bat = np.array([np.load(os.path.join(self.data_path, x), allow_pickle=True) for x in batch])\n",
    "        return np.array(bat[:,0]), np.array(bat[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = AugmentedDataset('train', batch_size)\n",
    "test_dataset = AugmentedDataset('test', batch_size)\n",
    "val_dataset = AugmentedDataset('val', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(test_dataset))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=train_dataset,\n",
    "                   steps_per_epoch = int(len(train_dataset) // batch_size),\n",
    "                   epochs = 10,\n",
    "                   verbose = 1,\n",
    "                   validation_data = val_dataset,\n",
    "                   validation_steps = int(len(val_dataset) // batch_size))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
